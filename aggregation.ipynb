{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def split_dataset():\n",
    "    string_judgment = 'judgment'\n",
    "    string_dataset = \"dataset\"\n",
    "\n",
    "    df_judgments = pd.read_csv('judgements_all.csv', delimiter='\\t', quoting =csv.QUOTE_MINIMAL)\n",
    "\n",
    "    print(\"column headers for dataframe: \")\n",
    "    print(df_judgments.keys())\n",
    "\n",
    "    dataset_list = df_judgments[string_dataset].unique().tolist()\n",
    "\n",
    "    for dataset_name in dataset_list:\n",
    "        unique_labels_of_dataset = df_judgments[df_judgments[string_dataset] == dataset_name][string_judgment].unique().tolist()\n",
    "        if np.nan in unique_labels_of_dataset:\n",
    "            print(dataset_name + \" has nan value\")\n",
    "        # print(dataset_name + str(unique_labels_of_dataset))\n",
    "\n",
    "    df_aggregated = df_judgments[df_judgments[string_dataset].isin(['WIC', 'Cosimlex', \"TempoWic\"])]\n",
    "\n",
    "    df_judgments = df_judgments[~df_judgments[string_dataset].isin(['WIC', 'Cosimlex', \"TempoWic\"])]\n",
    "\n",
    "\n",
    "    # df_judgements_with_vote_five = df_judgments[df_judgments[key_for_vote] == 5]\n",
    "    # print(df_judgements_with_vote_five[\"dataset\"].unique())\n",
    "\n",
    "    # df_usim = df_judgments[df_judgments['dataset'] == \"USim\"]\n",
    "    # df_judgments = df_judgments[df_judgments['dataset'] != \"USim\"]\n",
    "    # print(df_judgments[df_judgments['dataset'] == \"USim\"][\"judgment\"].unique())\n",
    "\n",
    "\n",
    "    # df_aggregated[key_for_vote].replace({'T': 1, 'F': 0}, inplace=True)\n",
    "\n",
    "    row_index_of_null_vote = df_judgments.loc[df_judgments[string_judgment].isnull()].index.tolist()\n",
    "    print(\"number of rows with nan judgment in dataset rushifteval_public: \" + str(len(row_index_of_null_vote)))\n",
    "\n",
    "    # csv_row_index_null_vote = [index + 2 for index in df_judgements.loc[df_judgements[key_for_vote].isnull()].index]\n",
    "    # print(df_judgements.iloc[csv_row_index_null_vote[0:5]])\n",
    "    # print(f\"The null value in column 'judgment' is located on csv row {csv_row_index_null_vote}.\")\n",
    "\n",
    "    complement =  ~df_judgments.index.isin(row_index_of_null_vote)\n",
    "\n",
    "    df_judgments[string_judgment][complement] = df_judgments[string_judgment][complement].astype(float)\n",
    "\n",
    "    df_judgments[string_judgment].replace({0.0: np.nan}, inplace=True)\n",
    "\n",
    "    # print(df_judgments[string_dataset].unique())\n",
    "\n",
    "    # print(df_judgments[string_judgment].unique())\n",
    "    # print(df_usim[\"judgment\"].unique())\n",
    "\n",
    "    # print(df_aggregated[string_judgment].unique())\n",
    "\n",
    "    return df_judgments, df_aggregated\n",
    "\n",
    "df_judgments, df_aggregated = split_dataset()\n",
    "print(df_aggregated.head())\n",
    "print(df_judgments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instances_with_multiple_annotations(df_judgments) -> dict:\n",
    "    \"\"\"\n",
    "    does not contain instance with only one annotation\n",
    "    \"\"\"\n",
    "    key_identifier_one = 'identifier1'\n",
    "    key_identifier_two = 'identifier2'\n",
    "    key_dataset = 'dataset'\n",
    "    key_judgment = \"judgment\"\n",
    "    dict_of_nonaggregated_instances = dict()\n",
    "    for index, row in df_judgments.iterrows():\n",
    "        composite_key = (row[key_dataset], row[key_identifier_one], row[key_identifier_two])\n",
    "        if composite_key not in dict_of_nonaggregated_instances:\n",
    "            dict_of_nonaggregated_instances[composite_key] = [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances[composite_key] = dict_of_nonaggregated_instances[composite_key] + [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "\n",
    "    dict_of_nonaggregated_instances_with_multiple_annotations = dict()\n",
    "    row_count = 0\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        if len(value) != 1:\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = value\n",
    "            row_count = row_count + len(value)\n",
    "        else:\n",
    "            row_count = row_count + 1\n",
    "    print(\"row_count: \" + str(row_count))\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "def get_dict_of_nonaggregated_instances(df_judgments) -> dict:\n",
    "    \"\"\"\n",
    "    contain instance with both one annotation or multiple annotations\n",
    "    \"\"\"\n",
    "    key_identifier_one = 'identifier1'\n",
    "    key_identifier_two = 'identifier2'\n",
    "    key_dataset = 'dataset'\n",
    "    key_judgment = \"judgment\"\n",
    "    key_lemma = \"lemma\"\n",
    "\n",
    "    dict_of_nonaggregated_instances = dict()\n",
    "    for index, row in df_judgments.iterrows():\n",
    "        composite_key = (row[key_dataset], row[key_identifier_one], row[key_identifier_two], row[key_lemma])\n",
    "        if composite_key not in dict_of_nonaggregated_instances:\n",
    "            dict_of_nonaggregated_instances[composite_key] = [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances[composite_key] = dict_of_nonaggregated_instances[composite_key] + [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def get_rows_of_instances_with_multiple_annotations(df_judgments) -> list:\n",
    "    rows_of_nonaggregated_instances_with_multiple_annotations = list()\n",
    "    key_identifier_one = 'identifier1'\n",
    "    key_identifier_two = 'identifier2'\n",
    "    key_dataset = 'dataset'\n",
    "    key_judgment = \"judgment\"\n",
    "    dict_of_nonaggregated_instances = dict()\n",
    "    for index, row in df_judgments.iterrows():\n",
    "        composite_key = (row[key_dataset], row[key_identifier_one], row[key_identifier_two])\n",
    "        if composite_key not in dict_of_nonaggregated_instances:\n",
    "            dict_of_nonaggregated_instances[composite_key] = [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances[composite_key] = dict_of_nonaggregated_instances[composite_key] + [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "\n",
    "    row_count = 0\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        if len(value) != 1:\n",
    "            for tuple_annotation in value:\n",
    "                rows_of_nonaggregated_instances_with_multiple_annotations.append(tuple_annotation[3])\n",
    "            row_count = row_count + len(value)\n",
    "        else:\n",
    "            row_count = row_count + 1\n",
    "    print(\"row_count: \" + str(row_count))\n",
    "    return rows_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "\n",
    "def get_votes_for_instances_with_multiple_annotations(df_judgments) -> dict:\n",
    "    \"\"\"\n",
    "    return a skeleton dict, the dict only contains info about instance with multiple annotations\n",
    "    \"\"\"\n",
    "    dict_of_nonaggregated_instances_with_multiple_annotations = get_instances_with_multiple_annotations(df_judgments)\n",
    "    for key, value in dict_of_nonaggregated_instances_with_multiple_annotations.items():\n",
    "        votes_list = list()\n",
    "        for tuple_annotation in value:\n",
    "            votes_list.append(tuple_annotation[-1])\n",
    "        votes_list.sort()\n",
    "        dict_of_nonaggregated_instances_with_multiple_annotations[key] = votes_list\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "\n",
    "def get_votes_for_nonaggregated_instances(df_judgments) -> dict:\n",
    "    \"\"\"\n",
    "    return a skeleton dict, the dict only contains info for both instance with multiple annotations and one annotation\n",
    "    \"\"\"\n",
    "    dict_of_nonaggregated_instances = get_dict_of_nonaggregated_instances(df_judgments)\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        votes_list = list()\n",
    "        for tuple_annotation in value:\n",
    "            votes_list.append(tuple_annotation[-1])\n",
    "        votes_list.sort()\n",
    "        dict_of_nonaggregated_instances[key] = votes_list\n",
    "    return dict_of_nonaggregated_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_median_rounding(dict_of_nonaggregated_instances_with_multiple_annotations: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances_with_multiple_annotations.items():\n",
    "        array = np.array(value)\n",
    "        median = np.nanmedian(array)\n",
    "        if not np.isnan(median):\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = float(round(median))\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = np.nan\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "# print(aggregation_median_rounding(get_votes_for_instances_with_multiple_annotations(df_judgments.head(2000))))\n",
    "\n",
    "def aggregation_median_exclusion(dict_of_nonaggregated_instances_with_multiple_annotations: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances_with_multiple_annotations.items():\n",
    "        array = np.array(value)\n",
    "        median = np.nanmedian(array)\n",
    "        if median.is_integer():\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = median\n",
    "        else:   \n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = np.nan\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "# print(aggregation_median_exclusion(get_votes_for_instances_with_multiple_annotations(df_judgments.head(2000))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning_remove_nan(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        if (np.nan in value):\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_remove_any_disagreements(dict_of_nonaggregated_instances: dict):\n",
    "    dict_of_nonaggregated_instances = cleaning_remove_nan(dict_of_nonaggregated_instances)\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if len(unique_labels_list) > 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "    return dict_of_nonaggregated_instances\n",
    "    \n",
    "def cleaning_allow_disagreements_in_one_point(dict_of_nonaggregated_instances: dict):\n",
    "    dict_of_nonaggregated_instances = cleaning_remove_nan(dict_of_nonaggregated_instances)\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if len(unique_labels_list) > 2:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if (len(unique_labels_list) == 2):\n",
    "            if abs(unique_labels_list[0] - unique_labels_list[1]) > 1:\n",
    "                dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_remove_instance_with_one_valid_vote(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if len(unique_labels_list) == 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_most_strict_condition(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if (np.nan in value):\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(unique_labels_list) > 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(value) == 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_second_strict_condition(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if (np.nan in value):\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(unique_labels_list) > 2:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if (len(unique_labels_list) == 2):\n",
    "            if abs(unique_labels_list[0] - unique_labels_list[1]) > 1:\n",
    "                dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(unique_labels_list) == 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_judgments, _ = split_dataset()\n",
    "df_judgments = df_judgments[df_judgments[\"dataset\"] == \"dwug_en\"]\n",
    "\n",
    "\n",
    "import copy\n",
    "['identifier1', 'identifier2', 'annotator', 'judgment', 'comment',\n",
    "       'lemma', 'dataset', 'language']\n",
    "string_identifier_one = \"identifier1\"\n",
    "string_identifier_two = 'identifier2'\n",
    "string_annotator = \"annotator\"\n",
    "string_judgment = \"judgment\"\n",
    "string_comment = \"comment\"\n",
    "string_lemma = \"lemma\"\n",
    "string_dataset = \"dataset\"\n",
    "string_language = \"language\"\n",
    "string_rounding = \"rounding\"\n",
    "string_exclusion = \"exclusion\"\n",
    "df_judgments[string_rounding] = \"not applicable\"\n",
    "df_judgments[string_exclusion] = \"not applicable\"\n",
    "\n",
    "dict_of_instances = get_votes_for_nonaggregated_instances(df_judgments)\n",
    "\n",
    "dict_of_instances = cleaning_most_strict_condition(dict_of_instances)\n",
    "\n",
    "\n",
    "\n",
    "dict_aggregation_median_rounding = aggregation_median_rounding(copy.copy((dict_of_instances)))\n",
    "dict_aggregation_median_exclusion = aggregation_median_exclusion(copy.copy(dict_of_instances))\n",
    "\n",
    "dict_of_aggregated_instances = dict()\n",
    "for key, value in dict_of_instances.items():\n",
    "    dict_of_aggregated_instances[key] = {string_rounding: dict_aggregation_median_rounding[key], string_exclusion: dict_aggregation_median_exclusion[key]}\n",
    "\n",
    "aggregated_rows = list()\n",
    "for key, value in dict_of_aggregated_instances.items():\n",
    "    row = {string_identifier_one: key[1], string_identifier_two: key[2], string_annotator: \"gold\", string_judgment:\"not applicable\", string_comment:\"gone through aggregation\", string_lemma: key[3], string_dataset: key[0], string_language: \"not applicable\", string_rounding:dict_of_aggregated_instances[key][string_rounding], string_exclusion:dict_of_aggregated_instances[key][string_exclusion]}\n",
    "    aggregated_rows.append(row)\n",
    "\n",
    "df_output = pd.DataFrame(aggregated_rows)\n",
    "df_output = df_output.replace(np.nan, 0.0)\n",
    "\n",
    "\n",
    "judgment_metric_to_use = \"exclusion\"\n",
    "\n",
    "min_judgment = df_output[judgment_metric_to_use].min()\n",
    "max_judgment = df_output[judgment_metric_to_use].max()\n",
    "num_bins = len(df_output[judgment_metric_to_use].unique())\n",
    "\n",
    "bin_edges = np.linspace(min_judgment - 0.5, max_judgment + 0.5, num_bins + 1)    \n",
    "# print(bin_edges)\n",
    "\n",
    "plt.figure(figsize=[6, 6])  # Adjust the figure size as desired\n",
    "_, _, bars = plt.hist(df_output[judgment_metric_to_use], bins=bin_edges,rwidth=0.8, color='b')\n",
    "plt.bar_label(bars, fontsize=10, color='navy')\n",
    "plt.xlabel('Judgment')\n",
    "plt.ylabel('Frequency', rotation=0, labelpad=30)\n",
    "plt.title(f'{len(df_output)} judgements')\n",
    "\n",
    "plt.show()  # Uncomment this line to display the plot\n",
    "\n",
    "# df_output.set_index([string_dataset, string_identifier_one, string_identifier_two], inplace=True)\n",
    "print(\"numebr of rows with non zero vote\", (df_output[judgment_metric_to_use] != 0).sum())\n",
    "\n",
    "string_token_index_one = \"token index 1\"\n",
    "string_token_index_two = \"token index 2\"\n",
    "string_context = \"context\"\n",
    "string_indexes_target_token = \"indexes_target_token\"\n",
    "\n",
    "pipeline_input_column_names = [string_lemma, \"sentence1\", string_token_index_one, \"sentence2\", string_token_index_two, string_judgment]\n",
    "df_pipeline_input = pd.DataFrame(columns=pipeline_input_column_names)\n",
    "\n",
    "df_uses = pd.read_csv('uses_all.csv', delimiter='\\t', quoting =csv.QUOTE_NONE)\n",
    "print(df_uses.columns)\n",
    "df_uses = df_uses.drop_duplicates()\n",
    "df_uses.set_index([string_dataset, string_lemma, \"identifier\"], inplace=True)\n",
    "\n",
    "\n",
    "# print(df_uses.head(1))\n",
    "\n",
    "count = 0\n",
    "for index, row in df_output.iterrows():\n",
    "    if row[judgment_metric_to_use] != 0:\n",
    "        sentence_one_key = (row[string_dataset], row[string_lemma], row[string_identifier_one])\n",
    "        sentence_two_key = (row[string_dataset], row[string_lemma], row[string_identifier_two])\n",
    "        new_row_in_df_pipeline_input = [row[string_lemma], df_uses.loc[sentence_one_key][string_context].values[0], df_uses.loc[sentence_one_key][string_indexes_target_token].values[0], df_uses.loc[sentence_two_key][string_context].values[0], df_uses.loc[sentence_two_key][string_indexes_target_token].values[0], row[judgment_metric_to_use]]\n",
    "        df_pipeline_input.loc[count] = new_row_in_df_pipeline_input  \n",
    "        count = count + 1\n",
    "   \n",
    "print(\"number of row:\", len(df_pipeline_input))\n",
    "df_pipeline_input.to_csv('instances_with_token_index.csv', sep='\\t', header=False, index=False, quoting=csv.QUOTE_NONE) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_judgments, _ = split_dataset()\n",
    "dict_of_nonaggregated_instances = get_votes_for_nonaggregated_instances(df_judgments)\n",
    "dict_of_nonaggregated_instances = cleaning_most_strict_condition(dict_of_nonaggregated_instances)\n",
    "\n",
    "\n",
    "count = 0\n",
    "instance = 0\n",
    "for key, value in dict_of_nonaggregated_instances.items():\n",
    "    instance = instance + 1\n",
    "    # print(instance)\n",
    "    if np.nan not in value:\n",
    "        if key[0]!= 'RuSemShift':\n",
    "            print(key, value)\n",
    "        count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_judgments, _ = split_dataset()\n",
    "df_dwug_de = df_judgments[df_judgments[\"dataset\"] == \"dwug_de\"]\n",
    "print(df_dwug_de[\"judgment\"].value_counts())\n",
    "\n",
    "result = df_judgments[(df_judgments['dataset'] == 'dwug_sv') & (df_judgments['judgment'] == 5)]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_judgments = df_judgments.replace(np.nan, 0.0)\n",
    "\n",
    "grouped = df_judgments.groupby('dataset')\n",
    "\n",
    "# Get the unique values of the 'dataset' column\n",
    "data_by_dataset = df_judgments['dataset'].unique()\n",
    "\n",
    "# Create a separate graph for each unique dataset\n",
    "for data in data_by_dataset:\n",
    "    # Get the subset of data for the current dataset\n",
    "    subset = grouped.get_group(data)\n",
    "    \n",
    "    min_judgment = subset['judgment'].min()\n",
    "    max_judgment = subset['judgment'].max()\n",
    "    num_bins = len(subset['judgment'].unique())\n",
    "\n",
    "    bin_edges = np.linspace(min_judgment - 0.5, max_judgment + 0.5, num_bins + 1)    \n",
    "    # print(bin_edges)\n",
    "    \n",
    "    plt.figure(figsize=[6, 6])  # Adjust the figure size as desired\n",
    "    _, _, bars = plt.hist(subset['judgment'], bins=bin_edges,rwidth=0.8, color='b')\n",
    "    plt.bar_label(bars, fontsize=10, color='navy')\n",
    "    plt.xlabel('Judgment')\n",
    "    plt.ylabel('Frequency', rotation=0, labelpad=30)\n",
    "    plt.title(f'Dataset {data}, {len(subset)} judgements')\n",
    "    \n",
    "    # plt.show()  # Uncomment this line to display the plot\n",
    "    # plt.savefig(f'dataset_{dataset}_hist.png')  # Uncomment this line to save the plot as an image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_judgments.groupby('language')\n",
    "\n",
    "data_by_language = df_judgments['language'].unique()\n",
    "\n",
    "for data in data_by_language:\n",
    "    subset = grouped.get_group(data)\n",
    "    \n",
    "    min_judgment = subset['judgment'].min()\n",
    "    max_judgment = subset['judgment'].max()\n",
    "    num_bins = len(subset['judgment'].unique())\n",
    "\n",
    "    bin_edges = np.linspace(min_judgment - 0.5, max_judgment + 0.5, num_bins + 1)    \n",
    "    # print(bin_edges)\n",
    "    \n",
    "    plt.figure(figsize=[6, 6])  # Adjust the figure size as desired\n",
    "    _, _, bars = plt.hist(subset['judgment'], bins=bin_edges,rwidth=0.8, color='b')\n",
    "    plt.bar_label(bars, fontsize=10, color='navy')\n",
    "    plt.xlabel('Judgment')\n",
    "    plt.ylabel('Frequency', rotation=0, labelpad=30)\n",
    "    plt.title(f'language {data}, {len(subset)} judgements')\n",
    "    \n",
    "    plt.show()  # Uncomment this line to display the plot\n",
    "    # plt.savefig(f'dataset_{dataset}_hist.png')  # Uncomment this line to save the plot as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_judgments, _ = split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_judgments.groupby('dataset')\n",
    "data_by_dataset = df_judgments['dataset'].unique()\n",
    "\n",
    "for data in data_by_dataset[:]:\n",
    "    subset = grouped.get_group(data)\n",
    "    total_judgments = len(subset)\n",
    "    language = str(subset['language'].unique())\n",
    "\n",
    "    concatenated = np.concatenate((subset['identifier1'].unique(), subset['identifier2'].unique()))\n",
    "    unique_identifiers = len(set(concatenated.tolist()))\n",
    "\n",
    "    print(f\"dataset: {data}, number of judgments: {total_judgments}, language in this set: {language}, number of words: {len(subset['lemma'].unique())}, number of sentences: {unique_identifiers}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
