{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def split_dataset():\n",
    "    string_judgment = 'judgment'\n",
    "    string_dataset = \"dataset\"\n",
    "\n",
    "    df_judgments = pd.read_csv('judgements_all.csv', delimiter=',', quoting =csv.QUOTE_MINIMAL)\n",
    "    # df_uses = pd.read_csv('uses_all.csv', delimiter='\\t', quoting =3)\n",
    "    # print(len(df_judgments))\n",
    "    # print(len(df_uses))\n",
    "\n",
    "    print(\"column headers for dataframe: \")\n",
    "    print(df_judgments.keys())\n",
    "\n",
    "    dataset_list = df_judgments[string_dataset].unique().tolist()\n",
    "\n",
    "    for dataset_name in dataset_list:\n",
    "        unique_labels_of_dataset = df_judgments[df_judgments[string_dataset] == dataset_name][string_judgment].unique().tolist()\n",
    "        if np.nan in unique_labels_of_dataset:\n",
    "            print(dataset_name + \" has nan value\")\n",
    "        # print(dataset_name + str(unique_labels_of_dataset))\n",
    "\n",
    "    df_aggregated = df_judgments[df_judgments[string_dataset].isin(['WIC', 'Cosimlex', \"TempoWic\"])]\n",
    "\n",
    "    df_judgments = df_judgments[~df_judgments[string_dataset].isin(['WIC', 'Cosimlex', \"TempoWic\"])]\n",
    "\n",
    "\n",
    "    # df_judgements_with_vote_five = df_judgments[df_judgments[key_for_vote] == 5]\n",
    "    # print(df_judgements_with_vote_five[\"dataset\"].unique())\n",
    "\n",
    "    # df_usim = df_judgments[df_judgments['dataset'] == \"USim\"]\n",
    "    # df_judgments = df_judgments[df_judgments['dataset'] != \"USim\"]\n",
    "    # print(df_judgments[df_judgments['dataset'] == \"USim\"][\"judgment\"].unique())\n",
    "\n",
    "\n",
    "    # df_aggregated[key_for_vote].replace({'T': 1, 'F': 0}, inplace=True)\n",
    "\n",
    "    row_index_of_null_vote = df_judgments.loc[df_judgments[string_judgment].isnull()].index.tolist()\n",
    "    print(\"number of rows with nan judgment in dataset rushifteval_public: \" + str(len(row_index_of_null_vote)))\n",
    "\n",
    "    # csv_row_index_null_vote = [index + 2 for index in df_judgements.loc[df_judgements[key_for_vote].isnull()].index]\n",
    "    # print(df_judgements.iloc[csv_row_index_null_vote[0:5]])\n",
    "    # print(f\"The null value in column 'judgment' is located on csv row {csv_row_index_null_vote}.\")\n",
    "\n",
    "    complement =  ~df_judgments.index.isin(row_index_of_null_vote)\n",
    "\n",
    "    df_judgments[string_judgment][complement] = df_judgments[string_judgment][complement].astype(float)\n",
    "\n",
    "    df_judgments[string_judgment].replace({0.0: np.nan}, inplace=True)\n",
    "\n",
    "    # print(df_judgments[string_dataset].unique())\n",
    "\n",
    "    # print(df_judgments[string_judgment].unique())\n",
    "    # print(df_usim[\"judgment\"].unique())\n",
    "\n",
    "    # print(df_aggregated[string_judgment].unique())\n",
    "\n",
    "    return df_judgments, df_aggregated\n",
    "\n",
    "df_judgments, df_aggregated = split_dataset()\n",
    "print(df_aggregated.head())\n",
    "print(df_judgments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instances_with_multiple_annotations(df_judgments):\n",
    "    key_identifier_one = 'identifier1'\n",
    "    key_identifier_two = 'identifier2'\n",
    "    key_dataset = 'dataset'\n",
    "    key_judgment = \"judgment\"\n",
    "    dict_of_nonaggregated_instances = dict()\n",
    "    for index, row in df_judgments.iterrows():\n",
    "        composite_key = (row[key_dataset], row[key_identifier_one], row[key_identifier_two])\n",
    "        if composite_key not in dict_of_nonaggregated_instances:\n",
    "            dict_of_nonaggregated_instances[composite_key] = [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances[composite_key] = dict_of_nonaggregated_instances[composite_key] + [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "\n",
    "    dict_of_nonaggregated_instances_with_multiple_annotations = dict()\n",
    "    row_count = 0\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        if len(value) != 1:\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = value\n",
    "            row_count = row_count + len(value)\n",
    "        else:\n",
    "            row_count = row_count + 1\n",
    "    print(\"row_count: \" + str(row_count))\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "def get_dict_of_nonaggregated_instances(df_judgments):\n",
    "    key_identifier_one = 'identifier1'\n",
    "    key_identifier_two = 'identifier2'\n",
    "    key_dataset = 'dataset'\n",
    "    key_judgment = \"judgment\"\n",
    "    dict_of_nonaggregated_instances = dict()\n",
    "    for index, row in df_judgments.iterrows():\n",
    "        composite_key = (row[key_dataset], row[key_identifier_one], row[key_identifier_two])\n",
    "        if composite_key not in dict_of_nonaggregated_instances:\n",
    "            dict_of_nonaggregated_instances[composite_key] = [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances[composite_key] = dict_of_nonaggregated_instances[composite_key] + [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def get_rows_of_instances_with_multiple_annotations(df_judgments):\n",
    "    rows_of_nonaggregated_instances_with_multiple_annotations = list()\n",
    "    key_identifier_one = 'identifier1'\n",
    "    key_identifier_two = 'identifier2'\n",
    "    key_dataset = 'dataset'\n",
    "    key_judgment = \"judgment\"\n",
    "    dict_of_nonaggregated_instances = dict()\n",
    "    for index, row in df_judgments.iterrows():\n",
    "        composite_key = (row[key_dataset], row[key_identifier_one], row[key_identifier_two])\n",
    "        if composite_key not in dict_of_nonaggregated_instances:\n",
    "            dict_of_nonaggregated_instances[composite_key] = [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances[composite_key] = dict_of_nonaggregated_instances[composite_key] + [tuple(list(composite_key) + [index, row[key_judgment]])]\n",
    "\n",
    "    row_count = 0\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        if len(value) != 1:\n",
    "            for tuple_annotation in value:\n",
    "                rows_of_nonaggregated_instances_with_multiple_annotations.append(tuple_annotation[3])\n",
    "            row_count = row_count + len(value)\n",
    "        else:\n",
    "            row_count = row_count + 1\n",
    "    print(\"row_count: \" + str(row_count))\n",
    "    return rows_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "# rows_of_nonaggregated_instances_with_multiple_annotations = get_rows_of_instances_with_multiple_annotations(df_judgments)\n",
    "# print(len(rows_of_nonaggregated_instances_with_multiple_annotations))\n",
    "\n",
    "# df_judgments_removing_instances_of_with_multiple_annotations = df_judgments.drop(rows_of_nonaggregated_instances_with_multiple_annotations)\n",
    "\n",
    "# print(len(get_rows_of_instances_with_multiple_annotations(df_judgments_removing_instances_of_with_multiple_annotations)))\n",
    "\n",
    "def get_votes_for_instances_with_multiple_annotations(df_judgments):\n",
    "    dict_of_nonaggregated_instances_with_multiple_annotations = get_instances_with_multiple_annotations(df_judgments)\n",
    "    for key, value in dict_of_nonaggregated_instances_with_multiple_annotations.items():\n",
    "        votes_list = list()\n",
    "        for tuple_annotation in value:\n",
    "            votes_list.append(tuple_annotation[-1])\n",
    "        votes_list.sort()\n",
    "        dict_of_nonaggregated_instances_with_multiple_annotations[key] = votes_list\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "# print(get_instances_with_multiple_annotations(df_judgments.head(2000)))\n",
    "# print(get_votes_for_instances_with_multiple_annotations(df_judgments.head(2000)))\n",
    "\n",
    "def get_votes_for_nonaggregated_instances(df_judgments):\n",
    "    dict_of_nonaggregated_instances = get_dict_of_nonaggregated_instances(df_judgments)\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        votes_list = list()\n",
    "        for tuple_annotation in value:\n",
    "            votes_list.append(tuple_annotation[-1])\n",
    "        votes_list.sort()\n",
    "        dict_of_nonaggregated_instances[key] = votes_list\n",
    "    return dict_of_nonaggregated_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_median_rounding(dict_of_nonaggregated_instances_with_multiple_annotations: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances_with_multiple_annotations.items():\n",
    "        array = np.array(value)\n",
    "        median = np.nanmedian(array)\n",
    "        if not np.isnan(median):\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = float(round(median))\n",
    "        else:\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = np.nan\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "# print(aggregation_median_rounding(get_votes_for_instances_with_multiple_annotations(df_judgments.head(2000))))\n",
    "\n",
    "def aggregation_median_exclusion(dict_of_nonaggregated_instances_with_multiple_annotations: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances_with_multiple_annotations.items():\n",
    "        array = np.array(value)\n",
    "        median = np.nanmedian(array)\n",
    "        if median.is_integer():\n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = median\n",
    "        else:   \n",
    "            dict_of_nonaggregated_instances_with_multiple_annotations[key] = np.nan\n",
    "    return dict_of_nonaggregated_instances_with_multiple_annotations\n",
    "\n",
    "# print(aggregation_median_exclusion(get_votes_for_instances_with_multiple_annotations(df_judgments.head(2000))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning_remove_nan(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        if (np.nan in value):\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_remove_any_disagreements(dict_of_nonaggregated_instances: dict):\n",
    "    dict_of_nonaggregated_instances = cleaning_remove_nan(dict_of_nonaggregated_instances)\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if len(unique_labels_list) > 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "    return dict_of_nonaggregated_instances\n",
    "    \n",
    "def cleaning_allow_disagreements_in_one_point(dict_of_nonaggregated_instances: dict):\n",
    "    dict_of_nonaggregated_instances = cleaning_remove_nan(dict_of_nonaggregated_instances)\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if len(unique_labels_list) > 2:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if (len(unique_labels_list) == 2):\n",
    "            if abs(unique_labels_list[0] - unique_labels_list[1]) > 1:\n",
    "                dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_remove_instance_with_one_valid_vote(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if len(unique_labels_list) == 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_most_strict_condition(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if (np.nan in value):\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(unique_labels_list) > 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(value) == 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "def cleaning_second_strict_condition(dict_of_nonaggregated_instances: dict):\n",
    "    for key, value in dict_of_nonaggregated_instances.items():\n",
    "        unique_labels_list = list(set(value))\n",
    "        if (np.nan in value):\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(unique_labels_list) > 2:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if (len(unique_labels_list) == 2):\n",
    "            if abs(unique_labels_list[0] - unique_labels_list[1]) > 1:\n",
    "                dict_of_nonaggregated_instances[key] = [np.nan for _ in range(len(value))]\n",
    "        if len(unique_labels_list) == 1:\n",
    "            dict_of_nonaggregated_instances[key] = [np.nan]\n",
    "    return dict_of_nonaggregated_instances\n",
    "\n",
    "# print(cleaning_remove_any_disagreements(get_votes_for_instances_with_multiple_annotations(df_judgments.head(2000))))\n",
    "# print(cleaning_allow_disagreements_in_one_point(get_votes_for_instances_with_multiple_annotations(df_judgments.head(2000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_judgments, _ = split_dataset()\n",
    "dict_of_nonaggregated_instances = get_votes_for_nonaggregated_instances(df_judgments)\n",
    "dict_of_nonaggregated_instances = cleaning_most_strict_condition(dict_of_nonaggregated_instances)\n",
    "\n",
    "\n",
    "count = 0\n",
    "instance = 0\n",
    "for key, value in dict_of_nonaggregated_instances.items():\n",
    "    instance = instance + 1\n",
    "    # print(instance)\n",
    "    if np.nan not in value:\n",
    "        if key[0]!= 'RuSemShift':\n",
    "            print(key, value)\n",
    "        count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_judgments, _ = split_dataset()\n",
    "df_dwug_de = df_judgments[df_judgments[\"dataset\"] == \"dwug_de\"]\n",
    "print(df_dwug_de[\"judgment\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
